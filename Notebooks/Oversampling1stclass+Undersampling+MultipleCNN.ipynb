{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a1e31f-bd85-45f7-904e-e8c1da93b0a6",
   "metadata": {},
   "source": [
    "# Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52225ff0-b69d-4c66-b804-e16a97e9c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import gc \n",
    "import numpy as np\n",
    "from scipy.ndimage import rotate\n",
    "from PIL import Image\n",
    "import torch\n",
    "import csv\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71322881-8668-40a5-84f3-0de9f845f45f",
   "metadata": {},
   "source": [
    "# Setting up GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd5d1ebb-b7d2-4245-abf3-937fbddd483e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e65449-a8c8-4fd3-966d-8b3d29a0a3d9",
   "metadata": {},
   "source": [
    "# Augmenting the images\n",
    "\n",
    "- Undersampled class 4 to 3000 images, and augmented only class 1 (lowest datasize) to 1000 (30%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d362c2ac-cec9-4b1f-a845-0d875e5395f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotation(image):\n",
    "    angle = np.random.choice([90, 180, 270])\n",
    "    return rotate(image, angle, axes=(0, 1), reshape=False, mode='reflect')\n",
    "\n",
    "    \n",
    "def load_images(folder_path, target_size=None):\n",
    "    \"\"\" Load all images from a folder and resize them if target_size is provided. \"\"\"\n",
    "    images = []\n",
    "    filenames = os.listdir(folder_path)\n",
    "    for filename in filenames:\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        with Image.open(img_path) as img:\n",
    "            if target_size:\n",
    "                img = img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "            images.append(np.array(img, dtype=np.float32))\n",
    "    return images, filenames\n",
    "\n",
    "def augment_images(data_gen, images, labels, batch_size, save_path, prefix, target_count):\n",
    "    \"\"\" Augment images and save them to a directory, stopping when the target count is reached. \"\"\"\n",
    "    generator = data_gen.flow(images, labels, batch_size=batch_size, save_to_dir=save_path, save_prefix=prefix, save_format='jpeg')\n",
    "    current_count = len(images)  \n",
    "    for i, (img_batch, label_batch) in enumerate(generator):\n",
    "        current_count += len(img_batch)  \n",
    "        if current_count >= target_count:  \n",
    "            print(f\"Target reached with batch {i}. Total count now {current_count}.\")\n",
    "            break\n",
    "        print(f\"Batch {i} saved, {len(img_batch)} images\")\n",
    "        gc.collect()  \n",
    "\n",
    "def generate_and_save_augmented_images(root_folder, save_folder, target_size=None, target_count=3000):\n",
    "    data_gen = ImageDataGenerator(\n",
    "        preprocessing_function=random_rotation,  \n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        zoom_range=0.4,\n",
    "        shear_range=20.0,\n",
    "        fill_mode='reflect'\n",
    "    )\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        save_path = os.path.join(save_folder, folder_name)\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)  # Ensure save directory exists\n",
    "        \n",
    "        images, filenames = load_images(folder_path, target_size=target_size)\n",
    "        labels = [folder_name] * len(images)\n",
    "        images_array = np.array(images)\n",
    "        labels_array = label_encoder.fit_transform(labels)\n",
    "        labels_array = to_categorical(labels_array)\n",
    "\n",
    "        current_count = len(images)\n",
    "        needed = target_count - current_count\n",
    "        print(f\"Processing {folder_name}, initial count: {current_count}, target: {target_count}, needed: {needed}\")\n",
    "        \n",
    "        if needed > 0:\n",
    "            batch_size = min(100, needed)\n",
    "            augment_images(data_gen, images_array, labels_array, batch_size, save_path, 'aug', target_count)\n",
    "\n",
    "root_folder = 'D:\\\\Datasets\\\\CropDiseaseClassificationOriginal\\\\split_crop_diseasev2\\\\train'\n",
    "save_folder = 'D:\\\\Datasets\\\\CropDiseaseClassificationOriginal\\\\split_crop_diseasev3\\\\train'\n",
    "\n",
    "generate_and_save_augmented_images(root_folder, save_folder, target_size=(224, 224), target_count=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f1d71-032c-4936-a0db-a12ee3adfc91",
   "metadata": {},
   "source": [
    "# Labelling with csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b84d06d-7c6e-4877-a19f-4133b1a63a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_csv(base_path,output_csv_file):\n",
    "    with open(output_csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Image Name\", \"Label\"])  \n",
    "    \n",
    "        for folder in os.listdir(base_path):\n",
    "            folder_path = os.path.join(base_path, folder)\n",
    "            \n",
    "            if os.path.isdir(folder_path):\n",
    "                for filename in os.listdir(folder_path):\n",
    "                    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                        writer.writerow([filename, folder])\n",
    "                    else:\n",
    "                        print(filename,folder,\"CHECKING!\")\n",
    "\n",
    "train_path = \"D:\\\\Datasets\\\\CropDiseaseClassificationOriginal\\\\split_crop_diseasev3\\\\train\"\n",
    "train_csv = \"D:\\\\Datasets\\\\CropDiseaseClassificationOriginal\\\\split_crop_diseasev3\\\\train\\\\image_labels.csv\"\n",
    "test_path = \"D:\\\\Datasets\\\\CropDiseaseClassificationOriginal\\\\split_crop_diseasev3\\\\test\"\n",
    "test_csv = \"D:\\\\Datasets\\\\CropDiseaseClassificationOriginal\\\\split_crop_diseasev3\\\\test\\\\image_labels.csv\"\n",
    "\n",
    "create_csv(train_path,train_csv)\n",
    "create_csv(test_path,test_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd2a7b8-2f13-4ad9-9161-821666c4d2af",
   "metadata": {},
   "source": [
    "# Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c332502d-aac1-4d86-b504-877ba8db620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "221b1adb-9a83-409c-9eb5-8934738ba1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'D:\\\\Datasets\\\\CropDiseaseClassificationOriginal\\\\split_crop_diseasev3\\\\train' \n",
    "testing_path = 'D:\\\\Datasets\\\\CropDiseaseClassificationOriginal\\\\split_crop_diseasev3\\\\test' \n",
    "train_dataset = ImageFolder(root=dataset_path, transform=transform)\n",
    "test_dataset = ImageFolder(root=testing_path, transform=transform)\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "pin_memory = True\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea7110ce-bdbf-4d4e-904d-1138afa3dcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.1590\n",
      "Epoch 2: Train Loss: 0.7686\n",
      "Epoch 3: Train Loss: 0.5290\n",
      "Epoch 4: Train Loss: 0.3305\n",
      "Epoch 5: Train Loss: 0.1781\n",
      "Epoch 6: Train Loss: 0.0858\n",
      "Epoch 7: Train Loss: 0.0486\n",
      "Epoch 8: Train Loss: 0.0304\n",
      "Epoch 9: Train Loss: 0.0179\n",
      "Epoch 10: Train Loss: 0.0154\n",
      "Epoch 11: Train Loss: 0.0131\n",
      "Epoch 12: Train Loss: 0.0171\n",
      "Epoch 13: Train Loss: 0.0086\n",
      "Epoch 14: Train Loss: 0.0078\n",
      "Epoch 15: Train Loss: 0.0075\n",
      "Epoch 16: Train Loss: 0.0064\n",
      "Epoch 17: Train Loss: 0.0051\n",
      "Epoch 18: Train Loss: 0.0046\n",
      "Epoch 19: Train Loss: 0.0065\n",
      "Epoch 20: Train Loss: 0.0044\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 5)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9)\n",
    "\n",
    "num_epochs=20\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    model.train()  \n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  \n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(images)  \n",
    "        loss = criterion(outputs, labels) \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        total_loss += loss.item() * images.size(0)\n",
    "    print(f'Epoch {epoch+1}: Train Loss: {total_loss / len(train_loader.dataset):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cc0bbd8-5d16-44cf-ad99-aaa93c9cfcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "     Cassava Bacterial Blight (CBB)       0.58      0.54      0.56       221\n",
      "Cassava Brown Streak Disease (CBSD)       0.74      0.75      0.74       431\n",
      "         Cassava Green Mottle (CGM)       0.74      0.72      0.73       493\n",
      "       Cassava Mosaic Disease (CMD)       0.82      0.84      0.83       528\n",
      "                            Healthy       0.62      0.64      0.63       466\n",
      "\n",
      "                           accuracy                           0.72      2139\n",
      "                          macro avg       0.70      0.70      0.70      2139\n",
      "                       weighted avg       0.72      0.72      0.72      2139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return all_labels, all_preds\n",
    "\n",
    "labels, preds = get_predictions(model, test_loader)\n",
    "print(classification_report(labels, preds, target_names=['Cassava Bacterial Blight (CBB)', 'Cassava Brown Streak Disease (CBSD)','Cassava Green Mottle (CGM)','Cassava Mosaic Disease (CMD)','Healthy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca792041-ac73-4aad-8e70-d53cb2975829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\miniconda3\\envs\\py310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdul\\miniconda3\\envs\\py310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.2645\n",
      "Epoch 2: Train Loss: 1.0841\n",
      "Epoch 3: Train Loss: 0.9758\n",
      "Epoch 4: Train Loss: 0.8946\n",
      "Epoch 5: Train Loss: 0.8908\n",
      "Epoch 6: Train Loss: 0.7882\n",
      "Epoch 7: Train Loss: 0.7336\n",
      "Epoch 8: Train Loss: 0.6361\n",
      "Epoch 9: Train Loss: 0.6081\n",
      "Epoch 10: Train Loss: 0.4891\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet152(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 5)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model = model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs): \n",
    "    model.train()  \n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  \n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(images)  \n",
    "        loss = criterion(outputs, labels)  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        total_loss += loss.item() * images.size(0)  \n",
    "    print(f'Epoch {epoch+1}: Train Loss: {total_loss / len(train_loader.dataset):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4fae224-903a-433a-ae4c-03eb72bcc486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CBB       0.44      0.24      0.31       221\n",
      "        CBSD       0.62      0.67      0.64       431\n",
      "         CGM       0.70      0.61      0.65       493\n",
      "         CMD       0.63      0.90      0.74       528\n",
      "     Healthy       0.57      0.45      0.50       466\n",
      "\n",
      "    accuracy                           0.62      2139\n",
      "   macro avg       0.59      0.57      0.57      2139\n",
      "weighted avg       0.61      0.62      0.60      2139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels, preds = get_predictions(model, test_loader)\n",
    "print(classification_report(labels, preds, target_names=['CBB', 'CBSD', 'CGM', 'CMD', 'Healthy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c47df1d-1224-490d-be31-5ec7baa882ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1 = nn.Linear(16 * 54 * 54, 120)  \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 20)\n",
    "        self.fc4 = nn.Linear(20, 5)#last layer 5 output classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 16 * 54 * 54)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3e8f99e-7384-4a2f-a740-a9a27dbfe10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.5918\n",
      "Epoch 2: Train Loss: 1.5659\n",
      "Epoch 3: Train Loss: 1.5442\n",
      "Epoch 4: Train Loss: 1.4991\n",
      "Epoch 5: Train Loss: 1.4405\n",
      "Epoch 6: Train Loss: 1.4008\n",
      "Epoch 7: Train Loss: 1.3681\n",
      "Epoch 8: Train Loss: 1.3370\n",
      "Epoch 9: Train Loss: 1.2830\n",
      "Epoch 10: Train Loss: 1.2282\n"
     ]
    }
   ],
   "source": [
    "model = CustomConvNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "num_epochs=10\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    model.train()  \n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  \n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(images)  \n",
    "        loss = criterion(outputs, labels) \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        total_loss += loss.item() * images.size(0)\n",
    "    print(f'Epoch {epoch+1}: Train Loss: {total_loss / len(train_loader.dataset):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94a18ff5-b7ee-4dcb-a2b8-b3222a22566c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CBB       0.21      0.59      0.31       221\n",
      "        CBSD       0.43      0.13      0.21       431\n",
      "         CGM       0.39      0.23      0.29       493\n",
      "         CMD       0.51      0.34      0.41       528\n",
      "     Healthy       0.27      0.43      0.33       466\n",
      "\n",
      "    accuracy                           0.32      2139\n",
      "   macro avg       0.36      0.35      0.31      2139\n",
      "weighted avg       0.38      0.32      0.31      2139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels, preds = get_predictions(model, test_loader)\n",
    "print(classification_report(labels, preds, target_names=['CBB', 'CBSD', 'CGM', 'CMD', 'Healthy']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
